#!/usr/bin/env python3
"""
EST CLI - Estimation Tool for Software Development Tasks
S·ª≠ d·ª•ng Atomic Agents v√† OpenAI ƒë·ªÉ ph√¢n t√≠ch t√†i li·ªáu v√† ∆∞·ªõc t√≠nh th·ªùi gian th·ª±c hi·ªán
"""

import os
import glob
import click
import openai
import pandas as pd
from pathlib import Path
from typing import List, Dict, Any
from datetime import datetime
from pydantic import BaseModel, Field
from atomic_agents import AtomicAgent, AgentConfig
import instructor

# Import config
from config.estimate import ESTConfig, SYSTEM_PROMPT_CONFIG, EXCEL_CONFIG

# Import context provider
from context_provider import EstimationContextManager


class Task(BaseModel):
    """M√¥ h√¨nh cho m·ªôt task con"""
    task_id: str = Field(..., description="ID duy nh·∫•t c·ªßa task")
    task_name: str = Field(..., description="T√™n task")
    description: str = Field(..., description="M√¥ t·∫£ chi ti·∫øt task")
    complexity: str = Field(..., description=f"ƒê·ªô ph·ª©c t·∫°p: {', '.join(ESTConfig.COMPLEXITY_LEVELS)}")
    estimated_hours: float = Field(..., description=f"Th·ªùi gian ∆∞·ªõc t√≠nh (gi·ªù, {ESTConfig.MIN_TASK_HOURS}-{ESTConfig.MAX_TASK_HOURS})")
    dependencies: List[str] = Field(default=[], description="Danh s√°ch task ID ph·ª• thu·ªôc")
    priority: str = Field(..., description=f"ƒê·ªô ∆∞u ti√™n: {', '.join(ESTConfig.PRIORITY_LEVELS)}")
    skills_required: List[str] = Field(default=[], description="K·ªπ nƒÉng c·∫ßn thi·∫øt")


class ParentTask(BaseModel):
    """M√¥ h√¨nh cho parent task"""
    parent_id: str = Field(..., description="ID duy nh·∫•t c·ªßa parent task")
    parent_name: str = Field(..., description="T√™n parent task")
    description: str = Field(..., description="M√¥ t·∫£ t·ªïng quan")
    total_estimated_hours: float = Field(..., description="T·ªïng th·ªùi gian ∆∞·ªõc t√≠nh")
    children_tasks: List[Task] = Field(..., description="Danh s√°ch c√°c task con")


class ProjectAnalysis(BaseModel):
    """M√¥ h√¨nh cho ph√¢n t√≠ch d·ª± √°n"""
    project_name: str = Field(..., description="T√™n d·ª± √°n")
    total_estimated_hours: float = Field(..., description="T·ªïng th·ªùi gian ∆∞·ªõc t√≠nh")
    parent_tasks: List[ParentTask] = Field(..., description="Danh s√°ch parent tasks")
    summary: str = Field(..., description="T√≥m t·∫Øt d·ª± √°n")
    assumptions: List[str] = Field(default=[], description="C√°c gi·∫£ ƒë·ªãnh")
    risks: List[str] = Field(default=[], description="C√°c r·ªßi ro")


class DocumentAnalysisInput(BaseModel):
    """Input schema cho vi·ªác ph√¢n t√≠ch t√†i li·ªáu"""
    documents: List[str] = Field(..., description="N·ªôi dung c√°c t√†i li·ªáu markdown")
    project_name: str = Field(..., description="T√™n d·ª± √°n")


class DocumentAnalysisOutput(BaseModel):
    """Output schema cho vi·ªác ph√¢n t√≠ch t√†i li·ªáu"""
    analysis: ProjectAnalysis = Field(..., description="K·∫øt qu·∫£ ph√¢n t√≠ch d·ª± √°n")


def read_markdown_files(folder_path: str) -> List[str]:
    """ƒê·ªçc t·∫•t c·∫£ file markdown t·ª´ folder"""
    documents = []
    
    # S·ª≠ d·ª•ng c·∫•u h√¨nh extensions
    for ext in ESTConfig.MARKDOWN_EXTENSIONS:
        pattern = os.path.join(folder_path, f"*{ext}")
        markdown_files = glob.glob(pattern)
        
        for file_path in markdown_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    documents.append(f"File: {os.path.basename(file_path)}\n{content}")
            except Exception as e:
                print(f"L·ªói khi ƒë·ªçc file {file_path}: {e}")
    
    return documents


def create_analysis_agent(openai_api_key: str, context_manager: EstimationContextManager = None) -> AtomicAgent:
    """T·∫°o agent ƒë·ªÉ ph√¢n t√≠ch t√†i li·ªáu v·ªõi context provider"""
    client = instructor.from_openai(openai.OpenAI(api_key=openai_api_key))
    
    # S·ª≠ d·ª•ng c·∫•u h√¨nh system prompt
    system_prompt = f"""B·∫°n l√† m·ªôt chuy√™n gia ph√¢n t√≠ch y√™u c·∫ßu ph·∫ßn m·ªÅm v√† ∆∞·ªõc t√≠nh th·ªùi gian ph√°t tri·ªÉn.

{chr(10).join(SYSTEM_PROMPT_CONFIG['background'])}

Nhi·ªám v·ª• c·ªßa b·∫°n:
{chr(10).join(f"{i+1}. {step}" for i, step in enumerate(SYSTEM_PROMPT_CONFIG['steps']))}

Y√™u c·∫ßu output:
{chr(10).join(f"- {instruction}" for instruction in SYSTEM_PROMPT_CONFIG['output_instructions'])}

IMPORTANT: S·ª≠ d·ª•ng th√¥ng tin t·ª´ context provider ƒë·ªÉ ƒë∆∞a ra ∆∞·ªõc t√≠nh ch√≠nh x√°c h∆°n d·ª±a tr√™n c√°c d·ª± √°n t∆∞∆°ng t·ª±."""
    
    # S·ª≠ d·ª•ng c·∫•u h√¨nh OpenAI v·ªõi greedy mode
    openai_config = ESTConfig.get_openai_config()
    
    # T·∫°o agent config v·ªõi context provider
    agent_config = AgentConfig(
        client=client,
        model=openai_config["model"],
        system_prompt=system_prompt,
        temperature=0.1,  # Low temperature for more consistent results
        max_tokens=4000   # Higher token limit for detailed analysis
    )
    
    # Add context provider if available
    if context_manager:
        agent_config.context_providers = [context_manager.context_provider]
    
    return AtomicAgent[DocumentAnalysisInput, DocumentAnalysisOutput](config=agent_config)


def validate_task_hours(analysis: ProjectAnalysis) -> List[str]:
    """Ki·ªÉm tra v√† b√°o c√°o c√°c task c√≥ th·ªùi gian kh√¥ng h·ª£p l·ªá"""
    warnings = []
    
    for parent in analysis.parent_tasks:
        for child in parent.children_tasks:
            if not ESTConfig.validate_task_hours(child.estimated_hours):
                warnings.append(
                    f"Task '{child.task_name}' c√≥ th·ªùi gian {child.estimated_hours}h "
                    f"(n·∫±m ngo√†i kho·∫£ng {ESTConfig.MIN_TASK_HOURS}-{ESTConfig.MAX_TASK_HOURS}h)"
                )
    
    return warnings


def export_to_excel(analysis: ProjectAnalysis, output_file: str):
    """Xu·∫•t k·∫øt qu·∫£ ph√¢n t√≠ch ra file Excel"""
    # T·∫°o DataFrame cho parent tasks
    parent_data = []
    for parent in analysis.parent_tasks:
        parent_data.append({
            EXCEL_CONFIG['parent_columns'][0]: parent.parent_id,
            EXCEL_CONFIG['parent_columns'][1]: parent.parent_name,
            EXCEL_CONFIG['parent_columns'][2]: parent.description,
            EXCEL_CONFIG['parent_columns'][3]: parent.total_estimated_hours,
            EXCEL_CONFIG['parent_columns'][4]: len(parent.children_tasks)
        })
    
    # T·∫°o DataFrame cho children tasks
    children_data = []
    for parent in analysis.parent_tasks:
        for child in parent.children_tasks:
            children_data.append({
                EXCEL_CONFIG['children_columns'][0]: parent.parent_id,
                EXCEL_CONFIG['children_columns'][1]: parent.parent_name,
                EXCEL_CONFIG['children_columns'][2]: child.task_id,
                EXCEL_CONFIG['children_columns'][3]: child.task_name,
                EXCEL_CONFIG['children_columns'][4]: child.description,
                EXCEL_CONFIG['children_columns'][5]: child.complexity,
                EXCEL_CONFIG['children_columns'][6]: child.estimated_hours,
                EXCEL_CONFIG['children_columns'][7]: ', '.join(child.dependencies) if child.dependencies else 'None',
                EXCEL_CONFIG['children_columns'][8]: child.priority,
                EXCEL_CONFIG['children_columns'][9]: ', '.join(child.skills_required) if child.skills_required else 'None'
            })
    
    # T·∫°o DataFrame cho summary
    summary_data = [{
        EXCEL_CONFIG['summary_columns'][0]: analysis.project_name,
        EXCEL_CONFIG['summary_columns'][1]: analysis.total_estimated_hours,
        EXCEL_CONFIG['summary_columns'][2]: len(analysis.parent_tasks),
        EXCEL_CONFIG['summary_columns'][3]: sum(len(parent.children_tasks) for parent in analysis.parent_tasks),
        EXCEL_CONFIG['summary_columns'][4]: datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    }]
    
    # T·∫°o Excel writer
    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
        # Sheet 1: Summary
        pd.DataFrame(summary_data).to_excel(writer, sheet_name=ESTConfig.EXCEL_SHEETS['summary'], index=False)
        
        # Sheet 2: Parent Tasks
        pd.DataFrame(parent_data).to_excel(writer, sheet_name=ESTConfig.EXCEL_SHEETS['parent_tasks'], index=False)
        
        # Sheet 3: Children Tasks
        pd.DataFrame(children_data).to_excel(writer, sheet_name=ESTConfig.EXCEL_SHEETS['children_tasks'], index=False)
        
        # Sheet 4: Assumptions & Risks
        assumptions_risks_data = []
        for assumption in analysis.assumptions:
            assumptions_risks_data.append({
                EXCEL_CONFIG['assumptions_risks_columns'][0]: 'Assumption', 
                EXCEL_CONFIG['assumptions_risks_columns'][1]: assumption
            })
        for risk in analysis.risks:
            assumptions_risks_data.append({
                EXCEL_CONFIG['assumptions_risks_columns'][0]: 'Risk', 
                EXCEL_CONFIG['assumptions_risks_columns'][1]: risk
            })
        
        if assumptions_risks_data:
            pd.DataFrame(assumptions_risks_data).to_excel(writer, sheet_name=ESTConfig.EXCEL_SHEETS['assumptions_risks'], index=False)
    
    print(f"‚úÖ ƒê√£ xu·∫•t k·∫øt qu·∫£ ra file: {output_file}")


@click.command()
@click.option('--folder', '-f', required=True, help='ƒê∆∞·ªùng d·∫´n ƒë·∫øn folder ch·ª©a file markdown')
@click.option('--output', '-o', default=ESTConfig.get_environment_config()['default_output'], help='T√™n file Excel output')
@click.option('--project-name', '-p', default=ESTConfig.get_environment_config()['default_project_name'], help='T√™n d·ª± √°n')
@click.option('--openai-key', envvar='OPENAI_API_KEY', help='OpenAI API Key')
@click.option('--use-semantic-search', is_flag=True, default=True, help='S·ª≠ d·ª•ng dsRAG semantic search ƒë·ªÉ c·∫£i thi·ªán ∆∞·ªõc t√≠nh')
@click.option('--greedy-mode', is_flag=True, default=True, help='S·ª≠ d·ª•ng greedy mode cho ∆∞·ªõc t√≠nh chi ti·∫øt')
def analyze_project(folder: str, output: str, project_name: str, openai_key: str, use_semantic_search: bool, greedy_mode: bool):
    """Ph√¢n t√≠ch t√†i li·ªáu markdown v√† ∆∞·ªõc t√≠nh th·ªùi gian th·ª±c hi·ªán d·ª± √°n"""
    
    if not openai_key:
        click.echo("‚ùå L·ªói: C·∫ßn cung c·∫•p OpenAI API Key qua --openai-key ho·∫∑c bi·∫øn m√¥i tr∆∞·ªùng OPENAI_API_KEY")
        return
    
    if not os.path.exists(folder):
        click.echo(f"‚ùå L·ªói: Folder {folder} kh√¥ng t·ªìn t·∫°i")
        return
    
    click.echo(f"üìÅ ƒêang ƒë·ªçc t√†i li·ªáu t·ª´ folder: {folder}")
    documents = read_markdown_files(folder)
    
    if not documents:
        click.echo("‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y file markdown n√†o trong folder")
        return
    
    click.echo(f"üìÑ ƒê√£ t√¨m th·∫•y {len(documents)} t√†i li·ªáu")
    
    # Kh·ªüi t·∫°o context manager v·ªõi dsRAG
    context_manager = None
    if use_semantic_search:
        click.echo("üîç ƒêang kh·ªüi t·∫°o dsRAG context provider...")
        context_manager = EstimationContextManager(openai_key)
        click.echo("‚úÖ dsRAG semantic search ƒë√£ ƒë∆∞·ª£c k√≠ch ho·∫°t")
    else:
        click.echo("‚ö†Ô∏è  Semantic search ƒë√£ b·ªã t·∫Øt")
    
    # T·∫°o agent ph√¢n t√≠ch v·ªõi context provider
    click.echo("ü§ñ ƒêang t·∫°o AI agent v·ªõi RAG context...")
    agent = create_analysis_agent(openai_key, context_manager)
    
    if greedy_mode:
        click.echo("üéØ Greedy mode ƒë√£ ƒë∆∞·ª£c k√≠ch ho·∫°t - ∆∞·ªõc t√≠nh chi ti·∫øt h∆°n")
    
    # Chu·∫©n b·ªã input
    input_data = DocumentAnalysisInput(
        documents=documents,
        project_name=project_name
    )
    
    # Ch·∫°y ph√¢n t√≠ch
    click.echo("üîç ƒêang ph√¢n t√≠ch t√†i li·ªáu v√† ∆∞·ªõc t√≠nh th·ªùi gian...")
    try:
        result = agent.run(input_data)
        analysis = result.analysis
        
        # Hi·ªÉn th·ªã k·∫øt qu·∫£ t√≥m t·∫Øt
        click.echo(f"\nüìä K·∫æT QU·∫¢ PH√ÇN T√çCH:")
        click.echo(f"T√™n d·ª± √°n: {analysis.project_name}")
        click.echo(f"T·ªïng th·ªùi gian ∆∞·ªõc t√≠nh: {analysis.total_estimated_hours:.1f} gi·ªù")
        click.echo(f"S·ªë parent tasks: {len(analysis.parent_tasks)}")
        total_children = sum(len(parent.children_tasks) for parent in analysis.parent_tasks)
        click.echo(f"S·ªë children tasks: {total_children}")
        
        # Ki·ªÉm tra validation
        warnings = validate_task_hours(analysis)
        if warnings:
            click.echo(f"\n‚ö†Ô∏è  C·∫¢NH B√ÅO - C√°c task c√≥ th·ªùi gian kh√¥ng h·ª£p l·ªá:")
            for warning in warnings:
                click.echo(f"   {warning}")
        
        # Hi·ªÉn th·ªã chi ti·∫øt parent tasks
        click.echo(f"\nüìã PARENT TASKS:")
        for i, parent in enumerate(analysis.parent_tasks, 1):
            click.echo(f"{i}. {parent.parent_name} ({parent.total_estimated_hours:.1f}h)")
            for child in parent.children_tasks:
                click.echo(f"   - {child.task_name} ({child.estimated_hours:.1f}h, {child.complexity})")
        
        # Xu·∫•t ra Excel
        export_to_excel(analysis, output)
        
        click.echo(f"\n‚úÖ Ho√†n th√†nh! K·∫øt qu·∫£ ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o: {output}")
        
    except Exception as e:
        click.echo(f"‚ùå L·ªói trong qu√° tr√¨nh ph√¢n t√≠ch: {e}")


if __name__ == '__main__':
    analyze_project()
